{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project name: Detecting exoplanets in outer space\n",
    "#### 1. Dataset: https://www.kaggle.com/keplersmachines/kepler-labelled-time-series-data/ \n",
    "#### 2. Model: Tensorflow Boosted Trees Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  1.13.1\n",
      "python interpreter and version:  3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print('tensorflow version: ',tf.__version__)\n",
    "import os\n",
    "import sys\n",
    "print('python interpreter and version: ', sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load kepler data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'detecting_exoplanets_in_outer_space.ipynb',\n",
       " 'exoTest.csv',\n",
       " 'exoTrain.csv']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsroot = 'C:\\\\Users\\\\peiya\\\\Desktop\\\\Quan\\\\detecting_exoplanets_in_outer_space';\n",
    "os.listdir(dsroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data \n",
      "    LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
      "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
      "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
      "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
      "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
      "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
      "\n",
      "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
      "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
      "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
      "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
      "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
      "\n",
      "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
      "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
      "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
      "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
      "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
      "\n",
      "[5 rows x 3198 columns]\n",
      "testing data \n",
      "    LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7  \\\n",
      "0      2   119.88   100.21    86.46    48.68    46.12    39.39    18.57   \n",
      "1      2  5736.59  5699.98  5717.16  5692.73  5663.83  5631.16  5626.39   \n",
      "2      2   844.48   817.49   770.07   675.01   605.52   499.45   440.77   \n",
      "3      2  -826.00  -827.31  -846.12  -836.03  -745.50  -784.69  -791.22   \n",
      "4      2   -39.57   -15.88    -9.16    -6.37   -16.13   -24.05    -0.90   \n",
      "\n",
      "    FLUX.8   FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
      "0     6.98     6.63  ...      14.52      19.29      14.44      -1.62   \n",
      "1  5569.47  5550.44  ...    -581.91    -984.09   -1230.89   -1600.45   \n",
      "2   362.95   207.27  ...      17.82     -51.66     -48.29     -59.99   \n",
      "3  -746.50  -709.53  ...     122.34      93.03      93.03      68.81   \n",
      "4   -45.20    -5.04  ...     -37.87     -61.85     -27.15     -21.18   \n",
      "\n",
      "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
      "0      13.33      45.50      31.93      35.78     269.43      57.72  \n",
      "1   -1824.53   -2061.17   -2265.98   -2366.19   -2294.86   -2034.72  \n",
      "2     -82.10    -174.54     -95.23    -162.68     -36.79      30.63  \n",
      "3       9.81      20.75      20.25    -120.81    -257.56    -215.41  \n",
      "4     -33.76     -85.34     -81.46     -61.98     -69.34     -17.84  \n",
      "\n",
      "[5 rows x 3198 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(os.path.join(dsroot, 'exoTrain.csv'))\n",
    "test = pd.read_csv(os.path.join(dsroot, 'exoTest.csv'))\n",
    "print('training data \\n', train.head())\n",
    "print('testing data \\n', test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop('LABEL', axis=1)\n",
    "y_train = train.LABEL-1 # TFBT estimator assumes labels starting with 0, in the datasets are 1 and 2 instead \n",
    "x_test = test.drop('LABEL', axis=1)\n",
    "y_test = test.LABEL-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow boosted trees model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_col_headers = x_train.columns.values.tolist() # save names of all features in a vector\n",
    "\n",
    "bc_fn = tf.feature_column.bucketized_column\n",
    "nc_fn = tf.feature_column.numeric_column\n",
    "\n",
    "buketized_features = [bc_fn(source_column=nc_fn(key=column),\n",
    "                           boundaries=[x_train[column].mean()])\n",
    "                     for column in numeric_col_headers]\n",
    "all_features = buketized_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "pi_fn = tf.estimator.inputs.pandas_input_fn\n",
    "train_input_fn = pi_fn(x=x_train,\n",
    "                      y=y_train,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      num_epochs=None)\n",
    "\n",
    "eval_input_fn = pi_fn(x=x_test,\n",
    "                      y=y_test,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=False,\n",
    "                      num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tfbtmodel', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001EDC3554EB8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "n_trees = 100\n",
    "n_steps = 100\n",
    "\n",
    "m_fn = tf.estimator.BoostedTreesClassifier\n",
    "model = m_fn(feature_columns=all_features,\n",
    "            n_trees=n_trees,\n",
    "            n_batches_per_layer=batch_size,\n",
    "            model_dir='./tfbtmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./tfbtmodel\\model.ckpt-18\n",
      "WARNING:tensorflow:From C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving checkpoints for 18 into ./tfbtmodel\\model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:loss = 0.6931472, step = 19\n",
      "INFO:tensorflow:Saving checkpoints for 118 into ./tfbtmodel\\model.ckpt.\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Loss for final step: 0.48012635.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x1edc35549e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_fn, steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From C:\\Users\\peiya\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:2002: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-05-16T12:02:29Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tfbtmodel\\model.ckpt-118\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-05-16-12:02:42\n",
      "INFO:tensorflow:Saving dict for global step 118: accuracy = 0.99122804, accuracy_baseline = 0.99122804, auc = 0.6925664, auc_precision_recall = 0.03408982, average_loss = 0.46484697, global_step = 118, label/mean = 0.00877193, loss = 0.46477324, precision = 0.0, prediction/mean = 0.36888078, recall = 0.0\n",
      "WARNING:tensorflow:Issue encountered when serializing resources.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'_Resource' object has no attribute 'name'\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 118: ./tfbtmodel\\model.ckpt-118\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9912280440330505\n",
      "accuracy_baseline: 0.9912280440330505\n",
      "auc: 0.6925663948059082\n",
      "auc_precision_recall: 0.034089818596839905\n",
      "average_loss: 0.46484696865081787\n",
      "global_step: 118\n",
      "label/mean: 0.008771929889917374\n",
      "loss: 0.4647732377052307\n",
      "precision: 0.0\n",
      "prediction/mean: 0.3688807785511017\n",
      "recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "for key, value in sorted(results.items()):\n",
    "    print('{}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
